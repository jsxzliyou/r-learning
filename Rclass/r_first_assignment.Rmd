---
title: "《R数据科学》 第一次作业"
author: "李游游"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    latex_engine: xelatex
    pandoc_args: ["--pdf-engine=xelatex", "--variable", "mainfont:Songti SC"]
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE ,error = FALSE, warning = FALSE, message = FALSE,
                      out.width = "100%", split = FALSE, fig.align = "center")
library(tidyverse)
library(ggplot2)
library(nycflights13)
library(kableExtra)
library(scales)
library(plotly)
library(patchwork)
library(ggrepel)
library(readxl) 
library(showtext)
showtext_auto(enable = TRUE)
```


# 第一题：探索nycflights13数据集


1. 从flights数据中找出到达时间延误2小时或者更多的所有航班，并将生成的新数据，保存为 flight_arr2hr。

如下面表格所示，展示出前10条示例数据
```{r}
flight_arr2hr <- flights %>% filter(arr_delay >= 120)
flight_arr2hr
```


2. 将生成的flight_arr2hr数据集根据目的地(dest)进行分组，统计出抵达每个目的地的航班数量，筛选出抵达航班数量前十名的目的地，将结果命名为 top10_dest。

如下面表格所示
```{r}
top10_dest <- flight_arr2hr %>% 
              group_by(dest) %>% 
              summarise(count = n()) %>%
              top_n(10, count)
top10_dest
```


3. 从 weather 表中挑选出以下变量:year, month, day, hour, origin, humid, wind_speed，并 将其与 flight_arr2hr 表根据共同变量进行左连接, 生成的新数据保存为 flight_weather

数据如下表所示
```{r}
weather1 <- weather %>% select(year, month, day, hour, origin, humid, wind_speed)
flight_weather <- flight_arr2hr %>% 
  left_join(weather1)
flight_weather
```


4. 基于 flight_weather 数据集，根据不同出发地(origin)在平行的三个图中画出风速wind_speed(x 轴)和出发延误时间dep_delay(y轴)的散点图，以及平滑曲线

如下图所示(去掉dep_delay高处离群点)
```{r}
# 去掉高处离群点
high_x <- quantile(flight_weather$dep_delay, 0.75) + 1.5*IQR(flight_weather$dep_delay)
flight_weather %>%
  filter(dep_delay < high_x) %>% 
  ggplot(aes(x = wind_speed, y = dep_delay)) +
  geom_point(position = "jitter") +
  geom_smooth() +
  facet_wrap(~ origin, nrow = 3)
```


5. flights中每家航空公司在2013年有多少班次的航班被取消了?提示:依据dep_time来判断某班次航班是否被取消

**每家航空公司在2013年的航班取消数据如下表，共有8255个班次被取消**
```{r}
cancelled_flights <- flights %>% 
  filter(year == 2013 & is.na(dep_time))
(cancelled_flights <- cancelled_flights %>% 
  group_by(carrier) %>% 
  summarise(cancelled_count = n()))
```


6. 找出flights中每一家航空公司的航班最常去的目的地机场，以及flights中每家航空公司飞往最常去的目的地机场的航班数量

结果如下表所示
```{r}
# 先统计每家航空公司每个目的地的航班数量
flights_grouped <- flights %>%  
  group_by(carrier, dest) %>%  
  summarise(flights_count = n()) %>% 
  arrange(carrier, desc(flights_count)) %>% 
  slice(1)
flights_grouped
```


# 第二题：数据连接及画图


1. 请将数据 hw1_a 和 hw1_b 分别读入 R，查看数据并指出各个变量的形式，最小值，最大值，中值，均值，标准差
```{r}
hw1_a <- read_excel("../data/hw1_a.xlsx")
hw1_b <- read_excel("../data/hw1_b.xlsx")


summary_report <- function(data, column) {
  var_class <- class(data[[column]])
  var_min <- min(data[[column]])
  var_max <- max(data[[column]])
  var_median <- median(data[[column]])
  var_mean <- mean(data[[column]])
  var_sd <- sd(data[[column]])
  
  print(paste("Variable ", column))
  print(paste("class: ", var_class))
  print(paste("min: ", var_min))
  print(paste("max: ", var_max))
  print(paste("median: ", var_median))
  print(paste("mean: ", var_mean))
  print(paste("sd: ", var_sd))
}

# 数据hw1_a
print("hw1_a details:")
summary_report(hw1_a, "ID")
summary_report(hw1_a, "Age")
summary_report(hw1_a, "Years_at_Employer")
summary_report(hw1_a, "Years_at_Address")
summary_report(hw1_a, "Income")

# 数据hw1_b
print("hw1_b details:")
summary_report(hw1_b, "ID")
summary_report(hw1_b, "Credit_Card_Debt")
summary_report(hw1_b, "Automobile_Debt")
summary_report(hw1_b, "Is_Default")
```


2. 结合上课我们所学的几种数据 join 的形式，尝试将两个数据集进行合并。对于每种数据合并的方式，请说明 key, 并且报告合并后的数据样本总行数

课堂上一共学习了常用的四种连接，内连接、左连接、右链接和全连接，还有两种不常用的筛选连接，分别如下：
```{r}
i_j_result <- hw1_a %>% 
  inner_join(hw1_b, by = "ID")
print(paste("hw1_a inner join hw1_b, by ID, row count: ", nrow(i_j_result)))
l_j_result <- hw1_a %>% 
  left_join(hw1_b, by = "ID")
print(paste("hw1_a left join hw1_b, by ID, row count: ", nrow(l_j_result)))
r_j_result <- hw1_a %>% 
  right_join(hw1_b, by = "ID")
print(paste("hw1_a right join hw1_b, by ID, row count: ", nrow(r_j_result)))
f_j_result <- hw1_a %>% 
  full_join(hw1_b, by = "ID")
print(paste("hw1_a full join hw1_b, by ID, row count: ", nrow(f_j_result)))

s_j_result <- hw1_a %>% 
  semi_join(hw1_b, by = "ID")
print(paste("hw1_a semi join hw1_b, by ID, row count: ", nrow(s_j_result)))
a_j_result <- hw1_a %>% 
  anti_join(hw1_b, by = "ID")
print(paste("hw1_a anti join hw1_b, by ID, row count: ", nrow(a_j_result)))

```


3. 请筛选出 hw1_a 中收入大于 4000 的样本，并将此样本和 hw1_b 中 Is_Default=1 的样本合并，你可以使用 inner join 的方式。这一问中你可以用 pipe 的形式

下表为结果示例
```{r}
filter(hw1_a, Income > 4000) %>% 
  inner_join(filter(hw1_b, Is_Default == 1), by = "ID")
```


4. 在第2问的基础上, 请给出Income对Years_at_Employer的散点图，你发现了哪些趋势和现象?
```{r}
question_4 <- i_j_result %>% 
  ggplot(aes(x = Years_at_Employer, y = Income)) +
  geom_point()
question_4
```
发现

-   整体上随着工作年限的增加收入程递增现象

-   10年以内增长趋势比较平缓，10年至20年增加相比于前者更加明显


5. 在第 4 问的基础上 按照 Is_Default 增加一个维度，请展示两变量在不同违约状态的散点图。请使用明暗程度作为区分方式
```{r}
i_j_result$Is_Default <- as.character(i_j_result$Is_Default)
l_j_result %>%
  filter(!is.na(Is_Default)) %>% 
  ggplot(aes(x = Years_at_Employer, y = Income, alpha = Is_Default)) +
  geom_point()
```


6. 对于第5问，请使用形状(shape)作为另外一种区分方式
```{r}
i_j_result %>% 
  ggplot(aes(x = Years_at_Employer, y = Income, shape = Is_Default)) +
  geom_point()
```


7. 请找出各个列的缺失值，并删除相应的行。请报告每一变量的缺失值个数，以及所有缺失值总数

如下表所示，在将hw1_a与hw1_b进行全连接后产生的缺失值个数（因为分别看每个表并没有缺失值）
```{r}
# 检测各列的缺失值  
missing_values <- apply(f_j_result, 2, is.na)  
# 输出每列的缺失值个数  
print(apply(missing_values, 2, sum))  
print(paste("NA count: ", sum(missing_values)))
# 删除包含缺失值的行  
l_j_result_clean <- na.omit(f_j_result)
# 输出删除后数据集的维度，确认没有缺失值的行  
print(paste("remove NA, count: ", nrow(l_j_result_clean)))
```


8. 找出 Income 中的极端值并滤掉对应行的数据
```{r}
#低处离群点：Q1 - 1.5IQR
low_point <- quantile(hw1_a$Income, 0.25) - 1.5*IQR(hw1_a$Income)
print(paste("Lower Outliers: ", low_point))
#高处离群点：Q3 + 1.5IQR
high_point <- quantile(hw1_a$Income, 0.75) + 1.5*IQR(hw1_a$Income)
print(paste("High Outliers: ", high_point))
```
去掉极端值自后的列表还有176行，数据示例如下表：
```{r}
# 去掉离群点数据
hw1_a_clean <- filter(hw1_a, Income <= high_point)
hw1_a_clean
```


9. 将 Income 对数化，并画出直方图和 density curve，你有什么发现?
```{r}
# 对数化收入列
income <- log(hw1_a$Income)
# 创建直方图和密度曲线
ggplot(data.frame(x = income), aes(x)) +
  geom_histogram(aes(y = ..density..), fill = "lightblue", color = "black") +
  geom_density(color = "red", size = 1) +
  geom_vline(xintercept = mean(income), color = "orange", linetype = "dashed")

```
发现

-   整体趋势大致符合正态分布，但又不完全符合，应该是数据来源并不是完全随机抽样





